{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import decisiontree as dt\n",
    "import pandas as pd\n",
    "import cPickle\n",
    "\n",
    "class Classifier(object):\n",
    "    \"\"\" Classe generique d'un classifieur\n",
    "        Dispose de 3 méthodes :\n",
    "            fit pour apprendre\n",
    "            predict pour predire\n",
    "            score pour evaluer la precision\n",
    "    \"\"\"\n",
    "    def fit(self,data,y):\n",
    "        raise NotImplementedError(\"fit non  implemente\")\n",
    "    def predict(self,data):\n",
    "        raise NotImplementedError(\"predict non implemente\")\n",
    "    def score(self,data,y):\n",
    "        return (self.predict(data)==y).mean()\n",
    "\n",
    "def v2m(x):\n",
    "    return x.reshape((x.size,1)) if len(x.shape)==1 else x\n",
    "\n",
    "def mod_labels(y,mod):\n",
    "    if(mod=='-1,1'):\n",
    "        return y*2-1\n",
    "    elif(mod=='0,1'):\n",
    "        return (y+1)/2\n",
    "    else:\n",
    "        print 'Error! Wrong mod for error.'\n",
    "        return None\n",
    "\n",
    "def cross_validation(model,x,y,k):\n",
    "    n=len(x)\n",
    "    index_perm=np.random.permutation(range(n))\n",
    "    scores=np.zeros((k))\n",
    "    x_perm=x[[index_perm]]\n",
    "    y_perm=y[[index_perm]]\n",
    "    for index in range(k):        \n",
    "        ik=int(float(index)*n/k)\n",
    "        ikp1=int(float(index+1)*n/k)\n",
    "        x_train=np.vstack((x_perm[:ik],x_perm[ikp1:]))\n",
    "        y_train=np.concatenate((y_perm[:ik],y_perm[ikp1:]))\n",
    "        x_test=x_perm[ik:ikp1]\n",
    "        model.fit(x_train,y_train)        \n",
    "        y_test=y_perm[ik:ikp1]\n",
    "        scores[index]=model.score(x_test,y_test)\n",
    "        #print('round '+str(index)+': '+str(scores[index])+'%.')\n",
    "    return scores.mean()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DecisionTree():\n",
    "    return dt.DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Bayes(Classifier):\n",
    "    def fit(self,x,y):\n",
    "        self.nb_classes=len(np.unique(y))\n",
    "        x_l=np.array([x[np.where(y==i)] for i in range(self.nb_classes)])\n",
    "        mean=[[np.mean(x_l[j][:,i]) for i in range(x_l[j].shape[1])] for j in range(self.nb_classes)]\n",
    "        std=[[np.std(x_l[j][:,i])+.1 for i in range(x_l[j].shape[1])] for j in range(self.nb_classes)]\n",
    "        self.mean=np.array(mean)\n",
    "        self.std=np.array(std)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        m,s=self.mean,self.std\n",
    "        maxllog=np.zeros((x.shape[0]))\n",
    "        for k in range(x.shape[0]):            \n",
    "            maxllog[k]=np.argmax([np.sum([np.log(1/(np.sqrt(2*np.pi)*s[j][i])*np.exp((-0.5*(float(x[k][i]-m[j][i])/s[j][i])**2))) for i in range(x.shape[1])]) for j in range(m.shape[0])])\n",
    "        return maxllog\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNN(Classifier):\n",
    "    def __init__(self,k=3):\n",
    "        self.k=k\n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "    def predict(self,z):\n",
    "        z_labels=np.zeros((len(z)))\n",
    "        for index,j in enumerate(z):\n",
    "            dist=np.array([np.linalg.norm(i-j) for i in self.x])\n",
    "            arg_dist=np.argsort(dist)[:self.k]\n",
    "            vote=self.y[arg_dist]\n",
    "            vote = vote.astype(int)\n",
    "            z_labels[index]=np.argmax(np.bincount(vote))\n",
    "            \n",
    "        return z_labels\n",
    "    \n",
    "    def hyperparam_plot(datax,datay,param_range=range(1,6)):\n",
    "        plt.figure(figsize=(7,7))\n",
    "        knn_score=np.zeros((len(param_range)))\n",
    "        for k in param_range:\n",
    "            knn=KNN(k=k)\n",
    "            knn_score[k-1]=self.cross_validation(datax,datay,8)\n",
    "        plt.plot(range(1,len(param_range)+1),knn_score,label='knn cross-val score')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge(x,y,w):\n",
    "    return np.maximum(0.,-(x.dot(w))*y)\n",
    "\n",
    "def hinge_grad(x,y,w):\n",
    "    return x*y\n",
    "\n",
    "Fonction = namedtuple(\"Fonction\",[\"f\",\"grad\",\"dim\"]) #declaration de la structure\n",
    "HINGE=Fonction(hinge,hinge_grad,6)\n",
    "\n",
    "class Perceptron(Classifier):\n",
    "    def __init__(self,loss=HINGE,max_iter=200,eps=0.00001):\n",
    "        self.max_iter,self.eps=max_iter,eps\n",
    "        self.w=None\n",
    "        self.loss=loss\n",
    "        \n",
    "    def fit(self,datax,datay):\n",
    "        datay=v2m(datay*2-1)\n",
    "        self.w=np.random.random((len(datax[0]),1))-0.5\n",
    "        self.max_iter=400\n",
    "        for t in range(self.max_iter):\n",
    "            hinge=self.loss[0](datax,datay,self.w)\n",
    "            index_pos=np.where(hinge>0.)[0]\n",
    "            grad=self.loss[1](datax,datay,self.w)\n",
    "            self.w+=self.eps*np.array([np.sum(grad[index_pos],axis=0)]).T\n",
    "        print 'hinge loss: '+str(np.sum(hinge))\n",
    "        print 'fit score: '+str((1.-float(len(np.where(hinge>0.)[0]))/len(datax))*100)+'%.'\n",
    "        \n",
    "    def predict(self,datax):\n",
    "         return (np.sign(datax.dot(self.w))+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x,l=1):\n",
    "    return 2*(1.0/(1.+np.exp(-l*x))-.5)\n",
    "    #return np.tanh(x)\n",
    "def dSigmoid(x,l=1):\n",
    "    return (l*np.exp(-l*x))/((1.0+np.exp(-l*x))**2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NN(Classifier):\n",
    "    def __init__(self,layers,eps=.2,max_iter=100000): #layer = [2,2,1] ds exemple\n",
    "        self.w = []\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            weight = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.w.append(weight)\n",
    "        weight = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.w.append(weight)\n",
    "        self.maxIter = max_iter\n",
    "        self.epsi = eps\n",
    "    def fit(self,x,y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        #biais ajouter au début sur les x\n",
    "        uns = np.atleast_2d(np.ones(x.shape[0]))\n",
    "        x = np.concatenate((uns.T, x), axis=1)\n",
    "        \n",
    "        for k in range(self.maxIter):\n",
    "            #batch\n",
    "            i = np.random.randint(x.shape[0])\n",
    "            a = [x[i]]\n",
    "\n",
    "            for l in range(len(self.w)):\n",
    "                    dot_value = np.dot(a[l], self.w[l])\n",
    "                    activation = sigmoid(dot_value)\n",
    "                    a.append(activation)\n",
    "            \n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            \n",
    "            deltas = [error * dSigmoid(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.w[l].T)*dSigmoid(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.w)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.w[i] += self.epsi*layer.T.dot(delta)\n",
    "\n",
    "            #if k % 10000 == 0: print 'itération:', k\n",
    "\n",
    "    def predict(self,x):\n",
    "        a = np.concatenate((np.atleast_2d(np.ones(x.shape[0])).T, np.array(x)), axis=1)      \n",
    "        for l in range(0, len(self.w)):\n",
    "                    \n",
    "            a = sigmoid(np.dot(a, self.w[l]))\n",
    "            \n",
    "        \n",
    "        return (np.sign(a))\n",
    "\n",
    "    def score(self,data,y):\n",
    "        return (self.predict(data).T[0]==y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
